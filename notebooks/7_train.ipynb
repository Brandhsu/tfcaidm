{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import set_path\n",
    "\n",
    "set_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tfcaidm import Jobs\n",
    "from tfcaidm import Model\n",
    "from tfcaidm import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When on the caidm servers, we can also specify a gpu to allocate using the `gpus` method from jarvis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Get hyperparameters\n",
    "2. Load a dataset\n",
    "3. Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoselect GPU (use only on caidm cluster)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2021-11-20 11:37:38 ] CUDA_VISIBLE_DEVICES automatically set to: 1           \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_PATH = \"/home/brandon/tfcaidm-pkg/configs/ymls/xr_pna/pipeline.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Get hyperparameters\n",
    "runs = Jobs(path=YAML_PATH)\n",
    "\n",
    "# --- Hyperparameters for N runs\n",
    "all_hyperparams = runs.get_params()\n",
    "\n",
    "# ---- Hyperparameters for first run\n",
    "hyperparams = all_hyperparams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env/path/root': 'exp',\n",
       " 'env/path/name': 'xr_pna',\n",
       " 'env/path/client': '/home/brandon/tfcaidm-pkg/configs/ymls/xr_pna/client.yml',\n",
       " 'model/model': 'unet',\n",
       " 'model/conv_type': 'conv',\n",
       " 'model/pool_type': 'conv',\n",
       " 'model/eblock': 'conv',\n",
       " 'model/elayer': 1,\n",
       " 'model/dblock': 'conv',\n",
       " 'model/depth': 4,\n",
       " 'model/width': 32,\n",
       " 'model/width_scaling': 1,\n",
       " 'model/kernel_size': [1, 3, 3],\n",
       " 'model/strides': [1, 2, 2],\n",
       " 'model/bneck': 2,\n",
       " 'model/branches': 4,\n",
       " 'model/atrous_rate': 6,\n",
       " 'model/order': 'rnc',\n",
       " 'model/norm': 'bnorm',\n",
       " 'model/activ': 'leaky',\n",
       " 'model/attn_msk': 'softmax',\n",
       " 'train/xs/dat': None,\n",
       " 'train/ys/pna/mask/name': 'msk',\n",
       " 'train/ys/pna/mask/remove_bg': True,\n",
       " 'train/ys/pna/mask/mask_weight': 1,\n",
       " 'train/ys/pna/mask/output_weight': 5,\n",
       " 'train/ys/pna/head': 'decoder_classifier',\n",
       " 'train/ys/pna/n_classes': 2,\n",
       " 'train/ys/pna/loss': 'sce',\n",
       " 'train/ys/pna/metric': 'dice',\n",
       " 'train/trainer/seed': 0,\n",
       " 'train/trainer/n_folds': 1,\n",
       " 'train/trainer/batch_size': 8,\n",
       " 'train/trainer/iters': 3000,\n",
       " 'train/trainer/steps': 100,\n",
       " 'train/trainer/valid_freq': 5,\n",
       " 'train/trainer/lr': 8e-05,\n",
       " 'train/trainer/lr_alpha': 0.25,\n",
       " 'train/trainer/lr_decay': 0.97,\n",
       " 'train/trainer/callbacks': ['checkpoint', 'lr_scheduler', 'tensorboard']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Dataset(hyperparams).get_client(fold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some test data by invoking `create_generators` using the jarvis client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train, gen_valid = client.create_generators(test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Model definition:\n",
    "\n",
    "```json\n",
    "{\n",
    "    'model/model': 'unet',\n",
    "    'model/conv_type': 'conv',\n",
    "    'model/pool_type': 'conv',\n",
    "    'model/eblock': 'conv',\n",
    "    'model/elayer': 1,\n",
    "    'model/dblock': 'conv',\n",
    "    'model/depth': 4,\n",
    "    'model/width': 32,\n",
    "    'model/width_scaling': 1,\n",
    "    'model/kernel_size': [1, 3, 3],\n",
    "    'model/strides': [1, 2, 2],\n",
    "    'model/bneck': 2,\n",
    "    'model/branches': 4,\n",
    "    'model/atrous_rate': 6,\n",
    "    'model/order': 'rnc',\n",
    "    'model/norm': 'bnorm',\n",
    "    'model/activ': 'leaky',\n",
    "    'model/attn_msk': 'softmax',\n",
    "}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Model(client)\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dat': <KerasTensor: shape=(None, 1, 512, 512, 1) dtype=float32 (created by layer 'dat')>,\n",
       " 'msk': <KerasTensor: shape=(None, 1, 512, 512, 1) dtype=float32 (created by layer 'msk')>,\n",
       " 'pna': <KerasTensor: shape=(None, 1, 512, 512, 1) dtype=uint8 (created by layer 'pna')>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nn.create()` method internally invokes `client.get_inputs(Input)`, builds a model defined in `client.hyperparams['model']`, and compiles it with the loss and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 512, 512, 32)\n",
      "(None, 1, 256, 256, 32)\n",
      "(None, 1, 128, 128, 32)\n",
      "(None, 1, 64, 64, 32)\n",
      "(None, 1, 32, 32, 32)\n",
      "(None, 1, 64, 64, 32)\n",
      "(None, 1, 128, 128, 32)\n",
      "(None, 1, 256, 256, 32)\n",
      "(None, 1, 512, 512, 32)\n"
     ]
    }
   ],
   "source": [
    "model = nn.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dat (InputLayer)                [(None, 1, 512, 512, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 1, 512, 512,  64          dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1, 512, 512,  128         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 1, 512, 512,  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 1, 512, 512,  9248        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1, 512, 512,  128         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 1, 512, 512,  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "eblock_0 (Lambda)               (None, 1, 512, 512,  0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 1, 512, 512,  9248        eblock_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 512, 512,  128         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 1, 512, 512,  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 1, 256, 256,  9248        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256, 256,  128         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 1, 256, 256,  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "eblock_1 (Lambda)               (None, 1, 256, 256,  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 1, 256, 256,  9248        eblock_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, 256, 256,  128         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1, 256, 256,  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 1, 128, 128,  9248        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 128, 128,  128         conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 1, 128, 128,  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "eblock_2 (Lambda)               (None, 1, 128, 128,  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 1, 128, 128,  9248        eblock_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 128, 128,  128         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1, 128, 128,  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 1, 64, 64, 32 9248        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 64, 64, 32 128         conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1, 64, 64, 32 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "eblock_3 (Lambda)               (None, 1, 64, 64, 32 0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 1, 64, 64, 32 9248        eblock_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 64, 64, 32 128         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1, 64, 64, 32 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 1, 32, 32, 32 9248        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 32, 32, 32 128         conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 1, 32, 32, 32 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "eblock_4 (Lambda)               (None, 1, 32, 32, 32 0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 1, 64, 64, 32 9248        eblock_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose (Conv3DTranspo (None, 1, 64, 64, 32 9248        eblock_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1, 64, 64, 32 128         conv3d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 64, 64, 32 128         conv3d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1, 64, 64, 32 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 1, 64, 64, 32 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1, 64, 64, 32 0           leaky_re_lu_11[0][0]             \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 1, 64, 64, 32 9248        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1, 64, 64, 32 128         conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 1, 64, 64, 32 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dblock_0 (Lambda)               (None, 1, 64, 64, 32 0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, 1, 128, 128,  9248        dblock_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, 1, 128, 128,  9248        dblock_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 128, 128,  128         conv3d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 128, 128,  128         conv3d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 1, 128, 128,  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 1, 128, 128,  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 1, 128, 128,  0           leaky_re_lu_14[0][0]             \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 1, 128, 128,  9248        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1, 128, 128,  128         conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 1, 128, 128,  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dblock_1 (Lambda)               (None, 1, 128, 128,  0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTrans (None, 1, 256, 256,  9248        dblock_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTrans (None, 1, 256, 256,  9248        dblock_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1, 256, 256,  128         conv3d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1, 256, 256,  128         conv3d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 1, 256, 256,  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 1, 256, 256,  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 1, 256, 256,  0           leaky_re_lu_17[0][0]             \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 1, 256, 256,  9248        tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1, 256, 256,  128         conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 1, 256, 256,  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dblock_2 (Lambda)               (None, 1, 256, 256,  0           leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_7 (Conv3DTrans (None, 1, 512, 512,  9248        dblock_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_6 (Conv3DTrans (None, 1, 512, 512,  9248        dblock_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1, 512, 512,  128         conv3d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 1, 512, 512,  128         conv3d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 1, 512, 512,  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 1, 512, 512,  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 1, 512, 512,  0           leaky_re_lu_20[0][0]             \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 1, 512, 512,  9248        tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1, 512, 512,  128         conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 1, 512, 512,  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dblock_3 (Lambda)               (None, 1, 512, 512,  0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "pna/logits (Conv3D)             (None, 1, 512, 512,  66          dblock_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pna (InputLayer)                [(None, 1, 512, 512, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msk (InputLayer)                [(None, 1, 512, 512, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pna/loss/sce (SparseCategorical ()                   0           pna[0][0]                        \n",
      "                                                                 msk[0][0]                        \n",
      "                                                                 pna/logits[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pna/metric/dice (DiceScore)     ()                   0           pna[0][0]                        \n",
      "                                                                 msk[0][0]                        \n",
      "                                                                 pna/logits[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 197,154\n",
      "Trainable params: 195,746\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfcaidm import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "\n",
    "The default fields for the trainer are:\n",
    "\n",
    "```python\n",
    "history = trainer.fit(\n",
    "    model,\n",
    "    gen_train,\n",
    "    gen_valid,\n",
    "    iters=100,\n",
    "    steps_per_epoch=10,\n",
    "    validation_freq=5,\n",
    "    callbacks=[],\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Setting optional kwargs (iters, steps_per_epoch, validation_freq) will override the values set in hyperparams[\"train\"][\"trainer].\n",
    "\n",
    "iters=100,\n",
    "steps_per_epoch=10,\n",
    "validation_freq=5,\n",
    "\n",
    "Setting callbacks=[] will use the callbacks from hyperparams[\"train\"][\"trainer]. Otherwise a list of callbacks can be passed in or None for no callbakcs.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 88s 797ms/step - loss: 0.3018 - pna/metric/dice/1: 0.3814\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 80s 802ms/step - loss: 0.2343 - pna/metric/dice/1: 0.5293\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 80s 804ms/step - loss: 0.2211 - pna/metric/dice/1: 0.5599\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 81s 806ms/step - loss: 0.2162 - pna/metric/dice/1: 0.5825\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.2113 - pna/metric/dice/1: 0.5695 - val_loss: 0.2302 - val_pna/metric/dice/1: 0.4608\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 81s 807ms/step - loss: 0.2059 - pna/metric/dice/1: 0.5590\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 81s 808ms/step - loss: 0.2024 - pna/metric/dice/1: 0.5691\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 0.2075 - pna/metric/dice/1: 0.5919\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 81s 809ms/step - loss: 0.1963 - pna/metric/dice/1: 0.5869\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.2038 - pna/metric/dice/1: 0.5909 - val_loss: 0.1887 - val_pna/metric/dice/1: 0.5827\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 81s 809ms/step - loss: 0.1924 - pna/metric/dice/1: 0.5986\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 0.2022 - pna/metric/dice/1: 0.5834\n",
      "Epoch 13/30\n",
      " 91/100 [==========================>...] - ETA: 7s - loss: 0.1884 - pna/metric/dice/1: 0.5931"
     ]
    }
   ],
   "source": [
    "history = trainer.fit(\n",
    "    model,\n",
    "    gen_train,\n",
    "    gen_valid,\n",
    "    iters=3000,\n",
    "    steps_per_epoch=100,\n",
    "    validation_freq=5,\n",
    "    callbacks=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Let's try out the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "\n",
    "Using the `imshow` function in jarvis we can visualize the model inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showall(x, figsize=(7,7)):\n",
    "    x = copy.deepcopy(x)\n",
    "    \n",
    "    for k in x:\n",
    "        if x[k].ndim >= 4:\n",
    "            if x[k].shape[-1] > 1:\n",
    "                x[k] = np.argmax(x[k], axis=-1)\n",
    "                x[k] = np.expand_dims(x[k], axis=-1)\n",
    "            imshow(x[k], title=k, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "Using the trained, hopefully generalized model, run a forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = next(gen_train)\n",
    "yhat = model(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showall(xs) # msk-pna is not actually passed in as an input, it is used for class weights..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showall(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_example(x, batch_index=0):\n",
    "    x = {k: np.expand_dims(x[k][batch_index], axis=0) for k in x if len(x[k].shape)}\n",
    "    \n",
    "    return x\n",
    "\n",
    "def show_example(x, y, xname, yname, batch_index=0, figsize=(5, 5)):\n",
    "    x = get_example(x, batch_index)[xname]\n",
    "    y = np.argmax(get_example(y, batch_index)[yname], axis=-1)\n",
    "    \n",
    "    imshow(x, y, figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(xs, yhat, \"dat\", \"pna/logits\", 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
